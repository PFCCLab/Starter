**问题1：** OCR量化任务的具体要求是什么？

答：OCR量化任务具体要求是把下面的OCR重点模型的量化跑通，并且量化的INT8权重和原始的FP32权重精度diff保持在1%之内（量化方法不限，顺序已排好，数据可以用公开数据，如果不能满足要求，找我获取）
PP-OCRv4_mobile_det
PP-OCRv4_mobile_rec
PP-OCRv4_server_det
PP-OCRv4_server_rec
PP-LCNet_x0_25_textline_ori
PP-FormulaNet-S
PP-FormulaNet-L
PP-LCNet_x1_0_doc_ori
PP-DocLayout-L
PP-DocLayout-S
SLANet_plus

> [PaddleX 快乐开源活动](https://github.com/PaddlePaddle/PaddleX/issues/3557)-PaddleX基础能力-OCR类模型的量化训练适配



**问题2：** 正在尝试对变分自编码器 VAE 进行精度验证，与torch相比，固定了输入和采样（在decode中使用均值采样）推理误差在e-4量级，不知道下一步该怎么进行精度对齐？

答：先确保都是fp32去对推理误差的，fp16 bf16底层实现本身有误差。这个误差算是比较小，可以直接推理出图看看再定



**问题3：** 每一次运行 VAE，对于同一输入，会有不同的输出，这对于精度对齐是否有影响，还是我忽略了一些随机过程？

答：有影响，必须保证多次运行 VAE，对于同一输入得到的输出是不变的。用二分法，在不同层级去断点打印，以及保存中间特征为npy再去加载成tensor去定位问题。

> [PaddleMIX 快乐开源活动](https://github.com/PaddlePaddle/PaddleMIX/issues/1046) MAR



**问题4：** 在将基于 pytorch 的模型迁移到 paddle 平台上实现过程中遇到了许多问题。例如：

        1. 不知道我模仿教程中做的权重转换是否正确
        2. 不知道 huggingface 中 DocOwl2 是如何在 pytorch 上如何实现的。其 huggingface 页面中有一个 quickstart，还没有尝试跑通。这可能导致对模型理解不够，就算将此模型在 paddle 平台上跑通，也只能说是凑巧。（https://huggingface.co/mPLUG/DocOwl2）
        3. 遇到了 TypeError: LlamaTokenizer.**init**() missing 1 required positional argument: 'vocab_file'。这显示我缺少了一个文件，但是我已经将 DocOwl2 在 huggingface 页面的所有文件都下载下来了，原本就没有 vocab_file。这个报错不知道怎么解决。

答：

1. 最基本的前提：推理时至少不会报错说维度不对，加载权重没有多余的报错。没推理出正常回答前无法确定，可能是权重转换有问题，或者是代码写的有问题。
2. huggingface 中 DocOwl2 给的torch例子代码必须先跑通，得到的结果才能作为paddlemix的参考。不理解的把论文pdf丢到 一言 kimi 豆包里去问和学习理解。
3. paddle的LlamaTokenizer 对于 vocab_file 可能和torch不同，把 tokenizer.model 备份下移出权重文件夹，然后下载这个文件试试 wget https://bj.bcebos.com/v1/paddlenlp/models/community/liuhaotian/llava-v1.5-7b/sentencepiece.bpe.model ，作用和 tokenizer.model 一样。

> [PaddleMIX 快乐开源活动](https://github.com/PaddlePaddle/PaddleMIX/issues/1046) NO.7 DocOwl2 模型推理



**问题5：** 无法确认转换后的权重是否正确；huggingface 中并没有给出任何python文件，我不知道需要编写或者修改哪些python文件使得模型能够在paddlePaddle运行

答：https://huggingface.co/lmms-lab/LLaVA-Video-7B-Qwen2 这主页里的Generation的代码要和 原始github https://github.com/LLaVA-VL/LLaVA-NeXT配合起来使用，先把pytorch代码权重推理跑通。
然后参照 https://github.com/PaddlePaddle/PaddleMIX/blob/develop/paddlemix/examples/llava_critic/run_predict.py 或者 https://github.com/PaddlePaddle/PaddleMIX/blob/develop/paddlemix/examples/llava/run_predict.py 写一个paddle的推理代码。
https://github.com/LLaVA-VL/LLaVA-NeXT/tree/main/llava/model 这里的代码和 这里对应 https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/models/llava 。如果paddlemix里没有实现的，就得再新加下。

> [PaddleMIX 快乐开源活动](https://github.com/PaddlePaddle/PaddleMIX/issues/1046)  进行 LLaVA-Video-7B-Qwen2 推理对齐

